{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52165030-66f6-414a-99be-de324b07c203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pycountry\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import seaborn as sns\n",
    "from jupyter_dash import JupyterDash\n",
    "from dash import dcc, html\n",
    "import dash_table\n",
    "from dash.dependencies import Input, Output\n",
    "import warnings\n",
    "import json\n",
    "import geopandas as gpd\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22601f45-221f-4859-b571-72b670b8f111",
   "metadata": {},
   "source": [
    "#### IMPORT DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2f1659b-28c8-4573-a637-dd1409720e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entity</th>\n",
       "      <th>Code</th>\n",
       "      <th>Annual CO₂ emissions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>1.055780e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>Africa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.432503e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>Africa (GCP)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.432492e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>Albania</td>\n",
       "      <td>ALB</td>\n",
       "      <td>5.173371e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>DZA</td>\n",
       "      <td>1.845581e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>Wallis and Futuna</td>\n",
       "      <td>WLF</td>\n",
       "      <td>3.001400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>World</td>\n",
       "      <td>OWID_WRL</td>\n",
       "      <td>3.729383e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>YEM</td>\n",
       "      <td>1.029614e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>7.521782e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>ZWE</td>\n",
       "      <td>1.042494e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Entity      Code  Annual CO₂ emissions\n",
       "Year                                                   \n",
       "2022        Afghanistan       AFG          1.055780e+07\n",
       "2022             Africa       NaN          1.432503e+09\n",
       "2022       Africa (GCP)       NaN          1.432492e+09\n",
       "2022            Albania       ALB          5.173371e+06\n",
       "2022            Algeria       DZA          1.845581e+08\n",
       "...                 ...       ...                   ...\n",
       "2022  Wallis and Futuna       WLF          3.001400e+04\n",
       "2022              World  OWID_WRL          3.729383e+10\n",
       "2022              Yemen       YEM          1.029614e+07\n",
       "2022             Zambia       ZMB          7.521782e+06\n",
       "2022           Zimbabwe       ZWE          1.042494e+07\n",
       "\n",
       "[247 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# READ IN GLOBAL CO2 EMISSIONS\n",
    "df_all_co2 = pd.read_csv(r'C:\\Users\\sydne\\Downloads\\MyWorld_Co2_Emissions.csv')\n",
    "\n",
    "df_all_co2.set_index('Year')\n",
    "df_all_co2['Entity'].unique()\n",
    "\n",
    "# Get dataset of emissions from most recent year\n",
    "df_co2 = df_all_co2[df_all_co2['Year'] == 2022]\n",
    "\n",
    "# Convert Country Names to Str\n",
    "df_cos = df_co2[~df_co2['Entity'].str.contains('GCP', na=False)]        # Drop columns that have GCP\n",
    "df_co2.set_index('Year')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fb4fabb-1a19-4671-b5d5-6644568098a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ IN ND GAIN\n",
    "df_risk = pd.read_csv(r'C:\\Users\\sydne\\Downloads\\gain.csv')\n",
    "drop_yrs = df_risk.columns[2:29].to_list()\n",
    "for col in drop_yrs:\n",
    "    df_risk.drop(col, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5875f031-e6b6-497f-85fc-a1f1b75a4d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes where the country codes are the same\n",
    "# this creates new rows for the two rows that match\n",
    "merged = pd.merge(df_co2, df_risk, left_on='Code', right_on='ISO3', how='outer')\n",
    "\n",
    "# Eliminate irrelevant entity rows\n",
    "options = r'(GCP|income|International|excl|(2|part)|Union|World)'\n",
    "merged = merged[~merged['Entity'].str.contains(options, na=False)]\n",
    "\n",
    "\n",
    "# drop other miscellaneous rows\n",
    "dropping_rows = r'(Antarctica|Bermuda|Christmas Island|Faroe Islands|French Polynesia|Greenland|Hong Kong|Kosovo|Macao|New Caledonia|Niue|Palestine|Saint Helena|Saint Pierre and Miquelon|South Sudan|Wallis and Futuna)'\n",
    "merged = merged[~merged['Entity'].str.contains(dropping_rows, na=False)]\n",
    "merged = merged[~merged['Entity'].isna() == True]    # dropping nan\n",
    "merged.drop(index = [1, 3, 7, 21, 25, 28], inplace = True)     # dropping continent rows\n",
    "\n",
    "\n",
    "# Edit columns\n",
    "merged.drop(['Year', 'ISO3', 'Name'], axis = 1, inplace = True)\n",
    "merged.columns = ['Entity', 'Code', 'CO2 Emissions', 'Risk']         \n",
    "\n",
    "# Get rows from merged df with at least 1 NaN\n",
    "nan_rows = merged.isna().any(axis = 1)\n",
    "nan_df = merged[nan_rows]\n",
    "nan_df = nan_df[~nan_df['Entity'].str.contains(dropping_rows, na=False)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1c6d21-cccc-4834-ab3d-f6ce84fb9458",
   "metadata": {},
   "source": [
    "### Setting Missing Climate Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99c402ab-5f65-4817-9fed-c7505581820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Liechtenstein's climate score = Austria's \n",
    "merged.loc[142].iloc[3] = merged[merged['Entity'] == 'Austria'].iloc[0,3]\n",
    "\n",
    "# Setting Anguilla's, Satin kitt's, Montserrat's, BVI's climate score = antigua\n",
    "merged.loc[35].iloc[3] = 49.075398 #merged[merged['Entity'] == 'Antigua and Barbuda'].iloc[0,3]        \n",
    "merged.loc[193].iloc[3] = merged[merged['Entity'] == 'Antigua and Barbuda'].iloc[0,3]\n",
    "merged.loc[160].iloc[3] = merged[merged['Entity'] == 'Antigua and Barbuda'].iloc[0,3]\n",
    "merged.loc[59].iloc[3] = merged[merged['Entity'] == 'Antigua and Barbuda'].iloc[0,3]\n",
    "\n",
    "# Setting Aruba, Bonaire, Curacao climate score = Barbados\n",
    "merged.loc[40].iloc[3] = merged[merged['Entity'] == 'Barbados'].iloc[0,3]\n",
    "merged.loc[55].iloc[3] = merged[merged['Entity'] == 'Barbados'].iloc[0,3]\n",
    "merged.loc[81].iloc[3]= merged[merged['Entity'] == 'Barbados'].iloc[0,3]\n",
    "\n",
    "# Setting Turks climate score = Bahamas\n",
    "merged.loc[230].iloc[3] = merged[merged['Entity'] == 'Bahamas'].iloc[0,3]\n",
    "\n",
    "# Setting Andorra's climate score = spain\n",
    "merged.loc[33].iloc[3]= merged[merged['Entity'] == 'Spain'].iloc[0,3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbd6df86-49ab-4438-b845-4aaaa5478eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resetting index\n",
    "df = merged.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37dc1c2-37ca-48a3-842d-3c29ad92e4c3",
   "metadata": {},
   "source": [
    "### Sync Dataframe with GeoJson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97d30b1d-86da-4feb-9aa8-b5adf274ab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path to your GeoJSON\n",
    "geo_path = r'C:\\Users\\sydne\\Downloads\\countries.geo.json'\n",
    "\n",
    "# Read and modify the GeoJSON\n",
    "with open(geo_path, 'r') as f:\n",
    "    geojson_data = json.load(f)  # Load GeoJSON into a Python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69fe4871-5c7a-4d59-be05-0d8f7c477b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat country names\n",
    "new_names = list()\n",
    "for feature in geojson_data['features']:\n",
    "    for code in df['Code']:\n",
    "        if feature['id'] == code:\n",
    "            # get index of current code\n",
    "            loc_index = df[df['Code'] == code].index[0]\n",
    "            value_index = df.index.get_loc(loc_index)\n",
    "            # replace name\n",
    "            df.iloc[value_index, 0] = feature['properties']['name']\n",
    "            new_names.append(feature['properties']['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "886d23d3-60b4-4a9d-a3c4-aab835984261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number places not found in geojson: 33\n",
      "~2/3 of these places are countries; rest are territories\n"
     ]
    }
   ],
   "source": [
    "# Determine which countries present in df but not in geojson\n",
    "not_present = list()\n",
    "code_list = df['Code']\n",
    "found = None\n",
    "for code in code_list:\n",
    "    found = False\n",
    "    for feature in geojson_data['features']:\n",
    "        if feature['id'] == code:\n",
    "            found = True\n",
    "    if found == False:\n",
    "        not_present.append(code)\n",
    "\n",
    "print('Number places not found in geojson:', len(not_present))\n",
    "print('~2/3 of these places are countries; rest are territories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0a23bd2-232c-48de-88d2-e2814203780a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Load the full GeoJSON dataset (downloaded from Natural Earth or similar sources)\\nworld = gpd.read_file(\"path_to_natural_earth_geojson_file.geojson\")\\n\\n# List of ISO3 codes for the 33 places\\niso3_codes = [\\n    \\'AND\\', \\'AIA\\', \\'ATG\\', \\'ABW\\', \\'BHR\\', \\'BRB\\', \\'BES\\', \\'VGB\\', \\'CPV\\', \\'COM\\',\\n    \\'COK\\', \\'CUW\\', \\'DMA\\', \\'GRD\\', \\'KIR\\', \\'LIE\\', \\'MDV\\', \\'MHL\\', \\'MUS\\', \\'FSM\\',\\n    \\'MSR\\', \\'NRU\\', \\'PLW\\', \\'KNA\\', \\'LCA\\', \\'VCT\\', \\'WSM\\', \\'STP\\', \\'SYC\\', \\'SGP\\',\\n    \\'TON\\', \\'TCA\\', \\'TUV\\'\\n]\\n\\n# Filter the dataset for the specified ISO3 codes\\nfiltered = world[world[\\'ISO_A3\\'].isin(iso3_codes)]\\n\\n# Save the filtered data to a new GeoJSON file\\nfiltered.to_file(\"filtered_locations.geojson\", driver=\"GeoJSON\")\\n\\nprint(\"Filtered GeoJSON file created successfully!\")\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### 33 countries are present in df, but not in geojson\n",
    "# RETURN TO THIS AFTER INTIAL MAPS CREATED\n",
    "'''\n",
    "# Load the full GeoJSON dataset (downloaded from Natural Earth or similar sources)\n",
    "world = gpd.read_file(\"path_to_natural_earth_geojson_file.geojson\")\n",
    "\n",
    "# List of ISO3 codes for the 33 places\n",
    "iso3_codes = [\n",
    "    'AND', 'AIA', 'ATG', 'ABW', 'BHR', 'BRB', 'BES', 'VGB', 'CPV', 'COM',\n",
    "    'COK', 'CUW', 'DMA', 'GRD', 'KIR', 'LIE', 'MDV', 'MHL', 'MUS', 'FSM',\n",
    "    'MSR', 'NRU', 'PLW', 'KNA', 'LCA', 'VCT', 'WSM', 'STP', 'SYC', 'SGP',\n",
    "    'TON', 'TCA', 'TUV'\n",
    "]\n",
    "\n",
    "# Filter the dataset for the specified ISO3 codes\n",
    "filtered = world[world['ISO_A3'].isin(iso3_codes)]\n",
    "\n",
    "# Save the filtered data to a new GeoJSON file\n",
    "filtered.to_file(\"filtered_locations.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "print(\"Filtered GeoJSON file created successfully!\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9e946e9-a1cb-4245-8251-f8af72517fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Some countries lacking emission data (because included in geojson, but not df)\n",
    "#### Some countries have emission data, but lacking location (because included in df but not geojson)\n",
    "\n",
    "\n",
    "# Adding counties only in geojson to df         \n",
    "add_countries = {'Entity': ['Antarctica', 'French Southern and Antarctic Lands', 'Bermuda', 'Falkland Islands', 'Greenland', 'French Guiana', 'Serbia and Montenegro', 'New Caledonia', 'Puerto Rico', 'Western Sahara', 'South Sudan', 'Palestine'], \n",
    "                'Code': ['ATA', 'ATF', 'BMU', 'FLK', 'GRL', 'GUF', 'CS-KM', 'NCL', 'PRI', 'ESH', 'SSD', 'PSE'], \n",
    "                'CO2 Emissions': [np.nan, np.nan,np.nan, np.nan,np.nan, np.nan,np.nan, np.nan,np.nan, np.nan,np.nan, np.nan], \n",
    "                'Risk': [np.nan, np.nan, np.nan, np.nan,np.nan, np.nan,np.nan, np.nan,np.nan, np.nan,np.nan, np.nan]}\n",
    "df = pd.concat([df, pd.DataFrame(add_countries)])    \n",
    "\n",
    "# Remove irrelevant entries from geojson (-99)\n",
    "geojson_data['features'] = [feature for feature in geojson_data['features'] if feature['id'] != '-99']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17e16773-3922-4615-87f8-b22133127608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the data with GeoJSON features\n",
    "for feature in geojson_data['features']:\n",
    "    geo_code = feature['id']  # assuming 'id' contains country code in GeoJSON\n",
    "    if geo_code in df['Code'].values:\n",
    "        # Merge the data by adding both emission and risk to the properties of the GeoJSON feature\n",
    "        emission = df.loc[df['Code'] == geo_code, 'CO2 Emissions'].values[0]\n",
    "        risk = df.loc[df['Code'] == geo_code, 'Risk'].values[0]\n",
    "        feature['properties']['CO2 Emissions'] = emission\n",
    "        feature['properties']['Risk'] = risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6b29301-d90e-4226-956f-ed1362721336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL CAN BE DELETED IF GEOJSON DATA IS FOUND FOR THE REMAINING 33 TERRITORIES/COUNTRIES IN THE DF\n",
    "# Extract the relevant data from geojson_data\n",
    "data = []\n",
    "for feature in geojson_data['features']:\n",
    "    data.append({\n",
    "        'id': feature['id'],  # Country code or ID\n",
    "        'name': feature['properties']['name'],  # Country name\n",
    "        'CO2 Emissions': feature['properties']['CO2 Emissions'],  # CO2 Emissions data\n",
    "        'Risk': feature['properties']['Risk']  # Risk data for hover\n",
    "    })\n",
    "\n",
    "geo_df = pd.DataFrame(data)\n",
    "geo_df.columns = ['Code', 'Entity', 'CO2 Emissions', 'Risk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "581de7dc-a7da-4bc3-a623-f50d3b412af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloropleth for CO2 \n",
    "\n",
    "fig1 = px.choropleth(geo_df,\n",
    "    geojson=geojson_data,\n",
    "    locations=[feature['id'] for feature in geojson_data['features']],  # List of country codes\n",
    "    color=[feature['properties']['CO2 Emissions'] for feature in geojson_data['features']],  # List of emissions values\n",
    "    color_continuous_scale='Viridis',  # Color scale for the emissions\n",
    "    labels={'color': 'CO2 Emissions'},  # Label for the color scale\n",
    "    hover_data = ['CO2 Emissions', 'Risk'],\n",
    "    hover_name = 'Entity',\n",
    "    title = 'Global CO2 Emissions'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a88b295-9099-42d9-8cc7-78063302102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choropleth for Risk\n",
    "fig2 = px.choropleth(geo_df, \n",
    "    geojson = geojson_data,\n",
    "    locations = [feature['id'] for feature in geojson_data['features']],  # List of country codes\n",
    "    color=[feature['properties']['Risk'] for feature in geojson_data['features']],  # List of emissions values\n",
    "    color_continuous_scale='Viridis',  # Color scale for the emissions\n",
    "    labels={'color': 'Risk'},  # Label for the color scale\n",
    "    hover_data = ['Risk', 'CO2 Emissions'],\n",
    "    hover_name = 'Entity',\n",
    "    title = 'Global Climate Risk'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c088de-9237-4fcc-a1d7-19e7c66c73b1",
   "metadata": {},
   "source": [
    "### Dash Application "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9283284-a28c-4524-bddb-74f8cb590c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1ea5b7d9fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n"
     ]
    }
   ],
   "source": [
    "# create a Dash Application\n",
    "app = JupyterDash(__name__)\n",
    "\n",
    "# Create the layout of the application (all graphs, dropdowns, text, charts)\n",
    "app.layout = html.Div(children = [\n",
    "\n",
    "    # Title of dashboard\n",
    "    html.H1('Global Climate Risk Analysis', style = {'textAlign':'center', 'fontSize':40, 'color':'black'}),\n",
    "    # Choropleth Maps\n",
    "    dcc.Graph(\n",
    "        id = 'emissions_choropleth', \n",
    "        figure = fig1,  \n",
    "    ),\n",
    "    dcc.Graph(\n",
    "        id = 'risk_choropleth', \n",
    "        figure = fig2,\n",
    "    )\n",
    "])\n",
    "\n",
    "# Create callback to update graph when input changes\n",
    "@app.callback(\n",
    "    # Output and input do not take keywords   [first element = id, second = component_property\n",
    "    [Output('emissions_choropleth', 'figure'), Output('risk_choropleth', 'figure')]\n",
    ")\n",
    "\n",
    "# function needed after the callback function\n",
    "def show_choropleths():\n",
    "    return fig1, fig2\n",
    "\n",
    "app.run_server('external')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87e146b-1c5b-46dc-a809-d79d0136e1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
